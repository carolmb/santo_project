{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cairocffi in /home/acmbrito/miniconda3/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.1.0 in /home/acmbrito/miniconda3/lib/python3.8/site-packages (from cairocffi) (1.14.0)\n",
      "Requirement already satisfied: pycparser in /home/acmbrito/miniconda3/lib/python3.8/site-packages (from cffi>=1.1.0->cairocffi) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install cairocffi\n",
    "import cairocffi\n",
    "import pandas as pd\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "\n",
    "header = '/mnt/e/MAG/mag-2021-01-05/advanced/'\n",
    "fields_affil = 'data_temp/paper_fields_of_study_byPaperID.txt'\n",
    "fields_schema = 'FieldOfStudyChildren.txt'\n",
    "fields_infos = 'FieldsOfStudy.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   paper_id   field_id     score\n",
      "0        15   15708023  0.341603\n",
      "1        15   17744445  0.314704\n",
      "2        15   86532276  0.389657\n",
      "3        23  141071460  0.433938\n",
      "4        23  177713679  0.433339\n",
      "   field_id  field_child_id\n",
      "0      4250       139676723\n",
      "1     12843         8105449\n",
      "2     12843        71383303\n",
      "3     12843       105805003\n",
      "4     12843       112019140\n",
      "   field_id   rank          normalized_name\n",
      "0    417682  16758                night air\n",
      "1   1443462  15557              immobiliser\n",
      "2   1576492  13013            matrix pencil\n",
      "3   2657588  13530   combinatorial topology\n",
      "4   3079626   8569  quantum electrodynamics\n"
     ]
    }
   ],
   "source": [
    "fields_affil_dd = dd.read_csv(fields_affil, header=None, sep='\\t', names=['paper_id', 'field_id', 'score'])\n",
    "print(fields_affil_dd.head())\n",
    "\n",
    "fields_schema_dd = pd.read_csv(header+fields_schema, header=None, sep='\\t', names=['field_id', 'field_child_id'])\n",
    "print(fields_schema_dd.head())\n",
    "\n",
    "pairs = []\n",
    "for idx,row in fields_schema_dd.iterrows():\n",
    "    try:\n",
    "        pairs.append((str(row['field_child_id']), str(row['field_id'])))\n",
    "    except:\n",
    "        print(row)\n",
    "        \n",
    "fields_infos_dd = pd.read_csv(header+fields_infos, header=None, sep='\\t')[[0, 1, 2]]\n",
    "fields_infos_dd.columns = ['field_id', 'rank', 'normalized_name']\n",
    "print(fields_infos_dd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fields_affil_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = set()\n",
    "for a,b in pairs:\n",
    "    nodes.add(a)\n",
    "    nodes.add(b)\n",
    "    \n",
    "fields_tree = ig.Graph(directed=True)\n",
    "fields_tree.add_vertices(len(nodes))\n",
    "fields_tree.vs['name'] = list(nodes)\n",
    "fields_tree.add_edges(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_out0 = [i for i, d in enumerate(fields_tree.degree(mode=ig.OUT)) if d == 0]\n",
    "print(len(idxs_out0))\n",
    "parents = [int(fields_tree.vs[i]['name']) for i in idxs_out0]\n",
    "print(idxs_out0[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print parents ids\n",
    "fields_infos_dd[fields_infos_dd['field_id'].isin(parents)].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_parent(g, v):\n",
    "    idxs = g.neighbors(v, mode=ig.OUT)\n",
    "    if len(idxs) == 0:\n",
    "        return [g.vs[v]['name']]\n",
    "    else:\n",
    "        temp = []\n",
    "        for i in idxs:\n",
    "            temp += path_to_parent(g, i)\n",
    "        return temp\n",
    "\n",
    "def get_parents(g, v):\n",
    "    temp = path_to_parent(g, v)\n",
    "    parents_str = ','.join(temp)\n",
    "    parents = [int(x) for x in temp]\n",
    "    return parents, parents_str\n",
    "\n",
    "# o parent é parent dele mesmo\n",
    "print(fields_tree.vs[1077])\n",
    "print(get_parents(fields_tree, 1077))\n",
    "\n",
    "# output_file = open('data/fields_of_study.csv', 'w')\n",
    "# for child in range(fields_tree.vcount()):\n",
    "#     parents_ids, parents_id_str = get_parents(fields_tree, child)\n",
    "#     parents_names = fields_infos_dd[fields_infos_dd[0].isin(parents_ids)][2].values\n",
    "#     child_mag_id = fields_tree.vs[child]['name']\n",
    "#     child_name = fields_infos_dd[fields_infos_dd[0] == int(child_mag_id)][2].values\n",
    "#     output_file.write('%s\\t%s\\t%s\\t%s\\n' % (child_name[0], child_mag_id, ','.join(parents_names), parents_id_str))\n",
    "    \n",
    "# output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# áreas que não estão na hierarquia\n",
    "a = set([int(t) for t in fields_tree.vs['name']]) # quem está na hierarquia\n",
    "b = set(fields_infos_dd['field_id'].values) # todas as áreas listadas no MAG\n",
    "c = b-a\n",
    "fields_infos_dd[fields_infos_dd['field_id'].isin(c)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_study = pd.read_csv('data/fields_of_study.csv', sep='\\t', header=None, names=['field', 'field_id', 'parents', 'parents_id'])\n",
    "fields_of_study.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_affil_dd = fields_affil_dd.merge(fields_of_study, how='left', on='field_id')\n",
    "fields_affil_dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields_affil_dd.to_csv('data_temp/FOS_split/fields_papers_*.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def div(dist):\n",
    "    dist = np.asarray(dist)\n",
    "    dist = dist/sum(dist)\n",
    "    div = np.exp(-np.sum((dist*np.log(dist))))\n",
    "    return np.rint(div)\n",
    "    \n",
    "def get_fos(row):\n",
    "    if row['weights'] != None:\n",
    "        w = json.loads(row['weights'])\n",
    "        if len(w) <= 0:\n",
    "            return ''\n",
    "        to_sort = []\n",
    "        for k,v in w.items():\n",
    "            to_sort.append((v, k))\n",
    "        fields = sorted(to_sort)\n",
    "#         max_key = max(w, key=lambda k: w[k])\n",
    "        n_fields = int(div(list(w.values())))\n",
    "        output = []\n",
    "        for f in fields[-n_fields:]:\n",
    "            output.append(f[1])\n",
    "        return ','.join(output)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'71924100,15744967'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = {'15744967': 2.772012987012987, '71924100': 0.5198051948051948, '144024400': 0.42848484848484847, '17744445': 0.2816666666666667, '138885662': 0.8715151515151516, '2908647359': 0.03333333333333333, '127413603': 0.025, '142362112': 0.06818181818181819}\n",
    "# d = {'121332964': 3.276230197909395, '127413603': 5.172747353593218, '86803240': 11.53172976529026, '15744967': 6.0951308819237004, '185592680': 2.100133654984465, '71924100': 23.08702061725509, '192562407': 3.0263360180152157, '41008148': 3.6679761904761903, '33923547': 0.5297222222222222, '138885662': 0.1, '142362112': 0.027777777777777776, '162324750': 0.0625, '144024400': 0.06523809523809523, '17744445': 0.20745722531436817, '205649164': 0.016666666666666666, '127313418': 0.03333333333333333}\n",
    "d = {\"15744967\": 0.85, \"71924100\": 0.15} \t\n",
    "get_fos({'weights':d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/AuthorsFOS_split/authors_fos_weights_2020_final_00000', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00001', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00002', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00003', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00004', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00005', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00006', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00007', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00008', 'data/AuthorsFOS_split/authors_fos_weights_2020_final_00009']\n",
      "   author_id                                            weights\n",
      "0        584  {\"15744967\": 2.772012987012987, \"71924100\": 0....\n",
      "1        859                                 {\"121332964\": 1.0}\n",
      "2        978  {\"138885662\": 3.64297619047619, \"142362112\": 3...\n",
      "3       1139  {\"142362112\": 1.5366666666666666, \"138885662\":...\n",
      "4       1799  {\"86803240\": 0.49384615384615393, \"71924100\": ...\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# for year in [2020]:\n",
    "year = 2020\n",
    "print(glob.glob('data/AuthorsFOS_split/authors_fos_weights_%d_final_*' % year)[:10])\n",
    "\n",
    "authors_fos = dd.read_csv('data/AuthorsFOS_split/authors_fos_weights_%d_final_*' % year, sep='\\t', header=None, names=['author_id', 'weights'])\n",
    "print(authors_fos.head())\n",
    "#     valid_authors = pd.read_csv('data/valid_authors_full.txt', header=None, names=['author_id', 'papers', 'cits'])\n",
    "#     valid_authors = valid_authors['author_id'].apply(int)\n",
    "#     valid_authors = valid_authors.values\n",
    "#     print(valid_authors[:10])\n",
    "\n",
    "#     authors_fos = authors_fos[authors_fos['author_id'].isin(valid_authors)]\n",
    "#     print(authors_fos.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id                                            weights  \\\n",
      "0        584  {\"15744967\": 2.772012987012987, \"71924100\": 0....   \n",
      "1        859                                 {\"121332964\": 1.0}   \n",
      "2        978  {\"138885662\": 3.64297619047619, \"142362112\": 3...   \n",
      "3       1139  {\"142362112\": 1.5366666666666666, \"138885662\":...   \n",
      "4       1799  {\"86803240\": 0.49384615384615393, \"71924100\": ...   \n",
      "\n",
      "                                                 fos  \n",
      "0              144024400,71924100,138885662,15744967  \n",
      "1                                          121332964  \n",
      "2  86803240,71924100,205649164,17744445,144024400...  \n",
      "3  95457728,15744967,17744445,138885662,144024400...  \n",
      "4                                  71924100,86803240  \n",
      "[########################################] | 100% Completed |  3hr  8min 14.0s\n"
     ]
    }
   ],
   "source": [
    "authors_fos['fos'] = authors_fos.apply(get_fos, axis=1, meta=('str'))\n",
    "print(authors_fos.head())\n",
    "# print(len(authors_fos), len(authors_fos['author_id'].unique()))\n",
    "    \n",
    "from dask.diagnostics import ProgressBar\n",
    "with ProgressBar():\n",
    "    authors_fos.to_csv('data/valid_authors_%d_fos_div_filter.csv' % year, sep='\\t', header=None, index=None, single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "fos = authors_fos_250k['fos']\n",
    "X = []\n",
    "for row in tqdm.tqdm(fos, total=len(valid_authors)):\n",
    "    X.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, count = np.unique(X, return_counts=True)\n",
    "for u,c in zip(unique, count):\n",
    "    print(u, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = [int(u) for u in unique]\n",
    "print(fields_infos_dd.head())\n",
    "unique_freq = fields_infos_dd[fields_infos_dd['field_id'].isin(unique)]\n",
    "unique_freq['count'] = unique_freq.apply(lambda row: count[ unique.index(row['field_id']) ], axis=1)\n",
    "print(unique_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_infos_dd = pd.read_csv(header+fields_infos, header=None, sep='\\t')[[0, 1, 2]]\n",
    "fields_infos_dd.to_csv('data/fields_names.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
